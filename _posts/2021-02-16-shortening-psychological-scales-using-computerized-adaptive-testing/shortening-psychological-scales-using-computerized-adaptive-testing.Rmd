---
title: "Shortening Psychological Scales Using Computerized Adaptive Testing"
description: |
  A short description of the post.
  ```{r, include=FALSE}
  bytes <- file.size("shortening-psychological-scales-using-computerized-adaptive-testing.Rmd")
  words <- bytes/10
  minutes <- words/200
  ``` 
  (`r round(minutes)` min read)
author:
  - name: Okan Bulut
    url: http://www.okanbulut.com/
    affiliation: University of Alberta
    affiliation_url: https://www.ualberta.ca
    orcid_id: 0000-0001-5853-1267
date: 02-16-2021
categories:
  - psychometrics
  - psychological scales
  - CAT
preview: computer.jpg
bibliography: cat.bib
csl: apa.csl
output:
  distill::distill_article:
    self_contained: false
    toc: true
draft: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, warning = FALSE, message = FALSE)
suppressWarnings({
  library("rmarkdown")
  library("kableExtra")
  library("emo")
  library("DataExplorer")
  library("ggplot2")
  library("gganimate")
  library("psych")
  library("mirt")
  library("catR")
})
```

![Photo by [Glenn Carstens-Peters](https://unsplash.com/@glenncarstenspeters) on [Unsplash](https://unsplash.com/)](computer.jpg)

## Introduction

In my previous posts, I demonstrated how to shorten measurement instruments automatically using methods such as [automated test assembly](https://okan.cloud/posts/2021-01-04-how-to-shorten-a-measurement-instrument-automatically-part-i/) and [the ant colony optimization](https://okan.cloud/posts/2021-01-19-how-to-shorten-a-measurement-instrument-automatically-part-ii/). These methods can help researchers and practitioners build a shorter version of a measurement instrument (e.g., tests, psychological scales, or surveys). 


## Computerized Adaptive Testing

xxx

## Example

In this example, we will use real data of a sample of respondents ($n = 4474$) who responded to the items in the [Taylor Manifest Anxiety Scale](https://openpsychometrics.org/tests/TMAS/) [@taylor1953] to build a computerized adaptive scale. The Taylor Manifest Anxiety Scale is often used as a measure of anxiety as a personality trait. Some items on the scale are negatively phrased and therefore have been reverse-coded^[Items 1, 3, 4, 9, 12, 15, 18, 20, 29, 32, 38, and 50 were reverse-coded.]. The final version of the data is available [here](https://raw.githubusercontent.com/okanbulut/blog/master/data_and_codes/tma_data.csv). Now let's import the data and check out its content. 


```{r, eval=FALSE}
# Import the TMA data into R
data <- read.csv("tma_data.csv", header = TRUE)

# Preview the data
head(data)
```

```{r, eval=TRUE, echo=FALSE}
data <- read.csv("tma_data.csv", header = TRUE)
paged_table(data, options = list(cols.print = 12))
```

Before we start using the data, we will check whether all of the items are psychometrically suitable. We will check the inter-item correlations and point-biserial correlations (i.e., item discrimination) to ensure that the items contribute to the scale sufficiently. 

```{r, eval = FALSE}
library("DataExplorer")

plot_correlation(data)
```

```{r corplot, eval = TRUE, echo=FALSE, fig.cap="Inter-item Correlations in the Taylor Manifest Anxiety Scale", fig.width=6, fig.height=6}
plot_correlation(data)
```

Figure \@ref(fig:corplot) shows that item 5 has a very low correlation with the rest of the items on the scale. Therefore, we will check item discrimination (i.e., point-biserial correlations) to examine whether this particular item might be problematic. We will use $r = 0.20$ as the threshold to identify problematic items. 

```{r, eval = FALSE}
library("ggplot2")
library("psych")

item_summary <- data.frame(Items = factor(colnames(data), levels = colnames(data)),
                           Discrimination = alpha(data)$item.stats$r.cor)

ggplot(data = item_summary, 
       aes(x = Items, y = Discrimination, colour = Discrimination > 0.20)) +
  geom_point(size = 3) + ylim(0, 1) +
  geom_hline(yintercept = 0.20, linetype="dashed", colour = "red", size = 1) +
  labs(x = "Items", "Discrimination") +
  coord_flip() +
  theme_bw()
```

```{r discplot, eval = TRUE, echo=FALSE, fig.cap="Item-total Correlations in the Taylor Manifest Anxiety Scale", fig.width=7, fig.height=6}
item_summary <- data.frame(Items = factor(colnames(data), levels = colnames(data)),
                           Discrimination = alpha(data)$item.stats$r.cor)

ggplot(data = item_summary, 
       aes(x = Items, y = Discrimination, colour = Discrimination > 0.20)) +
  geom_point(size = 3) + ylim(0, 1) +
  geom_hline(yintercept = 0.20, linetype="dashed", colour = "red", size = 1) +
  labs(x = "Items", "Discrimination") +
  coord_flip() +
  theme_bw()
```

Figure \@ref(fig:discplot) suggests that item 15 is correlated with the rest of the items on the scale and thus its discrimination value is below 0.20. We can also check the internal consistency of the scale, with and without this item, to see the impact of removing this particular item from the scale. 

```{r, echo=TRUE}
cat("Coefficient alpha with all items:", alpha(data)$total$raw_alpha)

cat("Coefficient alpha without item 15:", alpha(data)$alpha.drop$raw_alpha[15])
```

We can see that removing item 15 does not decrease the internal consistency of the scale; but rather it slightly increases the coefficient alpha. Therefore, we will leave item 15 out of the subsequent analyses.

```{r, echo=TRUE}
data <- data[,-c(15)]
```

Since CAT requires IRT-based item parameters, we will calibrate the items using a particular IRT model. The Taylor Manifest Anxiety Scale is not an achievement test and thus guessing would not be a concern. Thus, we will choose the 2-parameter logistic (2PL) model to calibrate the items and then save the estimated parameters as well as the theta (i.e., anxiety) scores.

```{r, eval = FALSE}
library("mirt")

# Model estimation
mod <- 'F = 1-49' 
model.2pl <- mirt(data=data, model=mod, itemtype="2PL", SE=TRUE)

# Saving item parameters as a matrix
parameters <- coef(model.2pl, IRTpars = TRUE, simplify=TRUE)$items
parameters <- as.matrix(parameters)
colnames(parameters) <- c("a","b","c","d")

# Saving theta values as a matrix
theta <- fscores(model.2pl, method = "EAP")
theta <- as.matrix(theta)
```

```{r, eval = TRUE, echo=FALSE}
# Model estimation
mod <- 'F = 1-49' 
model.2pl <- mirt(data=data, model=mod, itemtype="2PL", SE=TRUE, verbose=FALSE)

# Saving item parameters as a matrix
parameters <- coef(model.2pl, IRTpars = TRUE, simplify=TRUE)$items
parameters <- as.matrix(parameters)
colnames(parameters) <- c("a","b","c","d")

# Saving theta values as a matrix
theta <- fscores(model.2pl, method = "EAP")
theta <- as.matrix(theta)
```

Now we can check out the test information function for the scale. Figure \@ref(fig:tifplot) indicates that the scale is mostly informative between $\theta = -3$ and $\theta = -2$. 

```{r, eval = FALSE}
plot(model.2pl, type = 'infoSE', theta_lim=c(-5,5), 
     auto.key = list(points=TRUE, lines=TRUE, columns=2, space = "top"),
     par.settings = list(superpose.line = list(col = "black", lty = 1:2, lwd = 2)))
```

```{r tifplot, eval = TRUE, echo=FALSE, fig.cap="Test Information Function and Standard Error of Measurement"}
plot(model.2pl, type = 'infoSE', theta_lim=c(-5,5), 
     auto.key = list(points=TRUE, lines=TRUE, columns=2, space = "top"),
     par.settings = list(superpose.line = list(col = "black", lty = 1:2, lwd = 2)))
```

Using the item parameters and theta values we have estimated above, we will design a hypothetical CAT scenario. Our goal is to check the feasibility of using the Taylor Manifest Anxiety Scale as a computerized adaptive scale. Therefore, we will run post hoc simulations using real responses in the data. We will let the CAT system select the optimal items from the scale for each person and then compare the final theta estimates from CAT with those from the calibration that involves all 49 items. 

To run post hoc simulations, we will use the **catR** package [@catr].

```{r, eval = FALSE}
library("catR")
```

In the simulation, we will try the following rules:

* each person can answer up to 10 items in the scale, and 
* if a person's theta estimate is precise enough (i.e., SEM < 0.3), CAT should terminate the test before reaching 10 items. 

We will use Maximum Fisher Information (MFI) to select the starting item and the remaining items during the test. With MFI, CAT will choose the most informative item given a person's interim theta estimate. For ability estimation, we will use expected a posteriori (EAP) for estimating both interim theta values and final theta values.

Before starting the simulation with the whole data, we will test our CAT system using a single iteration. We will use the randomCAT function to simulate responses for a hypothetical person who takes the Taylor Manifest Anxiety Scale. We will assume that the person's true theta level is $\theta = 0$.

```{r}
sim1 <- randomCAT(trueTheta = 0, 
                  # Item bank
                  itemBank = parameters,
                  # Set the seed to ensure reproducibility
                  genSeed = 666,
                  # Starting rules for CAT 
                  start = list(startSelect="MFI"), 
                  # Test administration rules for CAT
                  test = list(method="EAP", itemSelect="MFI"),
                  # Stopping rule for CAT
                  stop = list(rule = c("precision", "length"), thr = c(0.3, 10)), 
                  # Final ability estimation
                  final = list(method = "EAP"),
                  # Save all interim theta and SEM values
                  allTheta = TRUE)
```

Now we can see how the response process worked for this hypothetical person. The plot_cat function will show how theta estimates and SEM values changed after administering each item^[This function has been inspired by the plot.cat function in the [xxIRT](https://cran.r-project.org/web/packages/xxIRT/index.html) package.]. 

```{r, eval=FALSE, echo=FALSE}
# plot_cat <- function(model) {
#   require("ggplot2")
#   
#   cat_summary <- data.frame(
#     items = factor(model$testItems, levels = model$testItems),
#     thetas = model$thetaProv,
#     se = model$seProv,
#     theta_lb = model$thetaProv - 1.96 * model$seProv,
#     theta_ub = model$thetaProv + 1.96 * model$seProv,
#     wr = factor(model$pattern, levels=c(0, 1), labels=c("Wrong", "Right")))
#   
#   p <- ggplot(data=cat_summary, aes(x=items, y=thetas, color=wr)) + 
#     geom_point(aes(size=se)) +
#     geom_linerange(aes(ymin=theta_lb, ymax=theta_ub), linetype=3, size = 1) +
#     geom_point(aes(x=tail(items, n = 1), y=tail(thetas, n = 1)), color="black", pch=4, size=4) +
#     geom_hline(aes(yintercept = model$trueTheta), color="#808080", linetype="dashed") +
#     coord_cartesian(ylim=c(-4, 4)) + 
#     scale_size_continuous(range=c(1, 3)) +
#     labs(x = "Items", y = expression(paste("Estimated ", theta)), color = "Response") +
#     guides(size=F, alpha=F) + 
#     theme_bw() + 
#     theme(legend.key=element_blank())
#   
#   return(p)
# }
# 
# plot_cat(sim1)
```

```{r catplot, fig.width=9, fig.height=6, fig.cap="Interim Theta and SEM Estimates in CAT"}
plot_cat <- function(model) {
  require("ggplot2")
  require("gganimate")
  
  cat_summary <- data.frame(
    items = factor(model$testItems, levels = model$testItems),
    thetas = model$thetaProv,
    theta_lb = model$thetaProv - 1.96 * model$seProv,
    theta_ub = model$thetaProv + 1.96 * model$seProv,
    wr = factor(model$pattern, levels=c(0, 1), labels=c("Wrong", "Right")))
  
  p1 <- ggplot(data=cat_summary, aes(x=items, y=thetas, color=wr)) + 
    geom_point(aes(group = seq_along(items)), size = 5) +
    geom_linerange(aes(ymin=theta_lb, ymax=theta_ub), size = 1.5, alpha = 0.4) +
    geom_point(aes(x=tail(items, n = 1), y=tail(thetas, n = 1)), color="black", pch=4, size=5) +
    geom_hline(aes(yintercept = model$trueTheta), 
               color="#808080", linetype="dotted", size = 1.5, alpha = 0.7) +
    transition_states(items)+
    coord_cartesian(ylim=c(-4, 4)) + 
    scale_size_continuous(range=c(1, 3)) +
    labs(x = "Items", y = expression(paste("Estimated ", theta)), color = "Response",
         caption = "Note: The dotted horizontal line represents the true theta level.") +
    guides(size=F, alpha=F) + 
    theme_bw(base_size = 19) + 
    theme(legend.key=element_blank(),
          plot.caption = element_text(hjust = 0))
  
  p2 <- animate(p1, 
                nframes = 250,
                fps = 25, 
                width = 900, 
                height = 600)
  
  return(p2)
}


plot_cat(sim1)
```


Figure \@ref(fig:catplot) shows that the 95% SEM band around the theta estimate is getting narrower after administering each item, indicating that the theta estimate is becoming more precise. The final theta estimate is shown with "X" on the right-hand side of the figure. After 10 items, the final theta estimate appears to be very close to the true theta value (i.e. dotted horizontal line).  

To run a post hoc CAT simulation with real responses in the data, we will use the simulateRespondents function in the **catR** package. To keep our example simple, we will choose a random sample of 1000 persons (out of 4474 persons) and test the CAT system with this sample. 

```{r, eval = TRUE, echo=TRUE, warning=FALSE, message=FALSE, results = 'hide'}
# Set the seed to ensure reproducibility
set.seed(2021)

# A random sample of 1000 persons
persons <- sample.int(1000, n = nrow(theta))

# Post hoc simulation #1
sim2 <- simulateRespondents(thetas = theta[persons,],
                            # Item bank
                            itemBank = parameters, 
                            # Real responses in the data
                            responsesMatrix = data[persons,],
                            # Starting rules for CAT  
                            start = list(startSelect="MFI"),
                            # Test administration rules for CAT
                            test = list(method="EAP", itemSelect="MFI"),
                            # Stopping rule for CAT
                            stop = list(rule = c("precision", "length"), thr = c(0.3, 10)),
                            # Final ability estimation
                            final = list(method = "EAP")
)
```

Now, let's see the simulation output.

```{r}
# Statistical summary of results
print(sim2)
```

```{r, eval=FALSE}
# Visual summary of results
plot(sim2)
```

```{r, echo = FALSE, fig.cap="Simulation Results", fig.width=7, fig.height=8}
# Visual summary of results
knitr::include_graphics("sim2_plot.png")
```

Next, let's keep all the design elements the same but increase the maximum number of items to 15. We will see if administering up to 15 items will reduce bias and RMSE and increase the correlation between true and estimated theta values.

```{r, eval = FALSE, echo=TRUE, warning=FALSE, message=FALSE, results = 'hide'}
# Post hoc simulation #2
sim3 <- simulateRespondents(thetas = theta[persons,],
                            # Item bank
                            itemBank = parameters, 
                            # Real responses in the data
                            responsesMatrix = data[persons,],
                            # Starting rules for CAT  
                            start = list(startSelect="MFI"),
                            # Test administration rules for CAT
                            test = list(method="EAP", itemSelect="MFI"),
                            # Stopping rule for CAT
                            stop = list(rule = c("precision", "length"), thr = c(0.3, 15)),
                            # Final ability estimation
                            final = list(method = "EAP")
)
```

Now, let's see the simulation output.

```{r, eval=FALSE}
# Statistical summary of results
print(sim3)
```

```{r, eval=FALSE, fig.width=7, fig.height=8}
# Visual summary of results
plot(sim3)
```

```{r, echo = FALSE, fig.cap="Simulation Results", fig.width=7, fig.height=8}
# Visual summary of results
knitr::include_graphics("sim3_plot.png")
```

## Conclusion

xx
