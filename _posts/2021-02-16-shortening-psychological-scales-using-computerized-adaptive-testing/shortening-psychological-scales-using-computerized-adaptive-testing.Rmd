---
title: "Shortening Psychological Scales Using Computerized Adaptive Testing"
description: |
  A short description of the post.
  ```{r, include=FALSE}
  bytes <- file.size("shortening-psychological-scales-using-computerized-adaptive-testing.Rmd")
  words <- bytes/10
  minutes <- words/200
  ``` 
  (`r round(minutes)` min read)
author:
  - name: Okan Bulut
    url: http://www.okanbulut.com/
    affiliation: University of Alberta
    affiliation_url: https://www.ualberta.ca
    orcid_id: 0000-0001-5853-1267
date: 02-16-2021
categories:
  - psychometrics
  - psychological scales
  - CAT
preview: computer.jpg
bibliography: cat.bib
csl: apa.csl
output:
  distill::distill_article:
    self_contained: false
    toc: true
draft: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, warning = FALSE, message = FALSE)
suppressWarnings({
  library("rmarkdown")
  library("kableExtra")
  library("emo")
  library("DataExplorer")
  library("ggplot2")
  library("psych")
  library("mirt")
  library("catR")
})
```

![Photo by [Glenn Carstens-Peters](https://unsplash.com/@glenncarstenspeters) on [Unsplash](https://unsplash.com/)](computer.jpg)

## Introduction

In my previous posts, I demonstrated how to shorten measurement instruments automatically using methods such as [automated test assembly](https://okan.cloud/posts/2021-01-04-how-to-shorten-a-measurement-instrument-automatically-part-i/) and [the ant colony optimization](https://okan.cloud/posts/2021-01-19-how-to-shorten-a-measurement-instrument-automatically-part-ii/). These methods can help researchers and practitioners build a shorter version of a measurement instrument (e.g., tests, psychological scales, or surveys). 


## Computerized Adaptive Testing

xxx

## Example

In this example, we will use real data of a sample of respondents ($n = 4474$) who responded to the items in the [Taylor Manifest Anxiety Scale](https://openpsychometrics.org/tests/TMAS/) [@taylor1953] to build a computerized adaptive scale. The Taylor Manifest Anxiety Scale is often used as a measure of anxiety as a personality trait. Some items on the scale are negatively phrased and therefore have been reverse-coded^[Items 1, 3, 4, 9, 12, 15, 18, 20, 29, 32, 38, and 50 were reverse-coded.]. The final version of the data is available [here](https://raw.githubusercontent.com/okanbulut/blog/master/data_and_codes/tma_data.csv). Now let's import the data and check out its content. 


```{r, eval=FALSE}
# Import the TMA data into R
data <- read.csv("tma_data.csv", header = TRUE)

# Preview the data
head(data)
```

```{r, eval=TRUE, echo=FALSE}
data <- read.csv("tma_data.csv", header = TRUE)
paged_table(data, options = list(cols.print = 12))
```

Before we start using the data, we will check whether all of the items are psychometrically suitable. We will check the inter-item correlations and point-biserial correlations (i.e., item discrimination) to ensure that the items contribute to the scale sufficiently. 

```{r, eval = FALSE}
library("DataExplorer")

plot_correlation(data)
```

```{r corplot, eval = TRUE, echo=FALSE, fig.cap="Inter-item Correlations in the Taylor Manifest Anxiety Scale", fig.width=6, fig.height=6}
plot_correlation(data)
```

Figure \@ref(fig:corplot) shows that item 5 has a very low correlation with the rest of the items on the scale. Therefore, we will check item discrimination (i.e., point-biserial correlations) to examine whether this particular item might be problematic. We will use $r = 0.20$ as the threshold to identify problematic items. 

```{r, eval = FALSE}
library("ggplot2")
library("psych")

item_summary <- data.frame(Items = factor(colnames(data), levels = colnames(data)),
                           Discrimination = alpha(data)$item.stats$r.cor)

ggplot(data = item_summary, 
       aes(x = Items, y = Discrimination, colour = Discrimination > 0.20)) +
  geom_point(size = 3) + ylim(0, 1) +
  geom_hline(yintercept = 0.20, linetype="dashed", colour = "red", size = 1) +
  labs(x = "Items", "Discrimination") +
  coord_flip() +
  theme_bw()
```

```{r discplot, eval = TRUE, echo=FALSE, fig.cap="Item-total Correlations in the Taylor Manifest Anxiety Scale", fig.width=7, fig.height=6}
item_summary <- data.frame(Items = factor(colnames(data), levels = colnames(data)),
                           Discrimination = alpha(data)$item.stats$r.cor)

ggplot(data = item_summary, 
       aes(x = Items, y = Discrimination, colour = Discrimination > 0.20)) +
  geom_point(size = 3) + ylim(0, 1) +
  geom_hline(yintercept = 0.20, linetype="dashed", colour = "red", size = 1) +
  labs(x = "Items", "Discrimination") +
  coord_flip() +
  theme_bw()
```

Figure \@ref(fig:discplot) suggests that item 15 is correlated with the rest of the items on the scale and thus its discrimination value is below 0.20. We can also check the internal consistency of the scale, with and without this item, to see the impact of removing this particular item from the scale. 

```{r, echo=TRUE}
cat("Coefficient alpha with all items:", alpha(data)$total$raw_alpha)

cat("Coefficient alpha without item 15:", alpha(data)$alpha.drop$raw_alpha[15])
```

We can see that removing item 15 does not decrease the internal consistency of the scale; but rather it slightly increases the coefficient alpha. Therefore, we will leave item 15 out of the subsequent analyses.

```{r, echo=TRUE}
data <- data[,-c(15)]
```

Since CAT requires IRT-based item parameters, we will calibrate the items using a particular IRT model. The Taylor Manifest Anxiety Scale is not an achievement test and thus guessing would not be a concern. Thus, we will choose the 2-parameter logistic (2PL) model to calibrate the items and then save the estimated parameters as well as the theta (i.e., anxiety) scores.

```{r, eval = FALSE}
library("mirt")

# Model estimation
mod <- 'F = 1-49' 
model.2pl <- mirt(data=data, model=mod, itemtype="2PL", SE=TRUE)

# Saving item parameters as a matrix
parameters <- coef(model.2pl, IRTpars = TRUE, simplify=TRUE)$items
parameters <- as.matrix(parameters)
colnames(parameters) <- c("a","b","c","d")

# Saving theta values as a matrix
theta <- fscores(model.2pl, method = "EAP")
theta <- as.matrix(theta)
```

```{r, eval = TRUE, echo=FALSE}
# Model estimation
mod <- 'F = 1-49' 
model.2pl <- mirt(data=data, model=mod, itemtype="2PL", SE=TRUE, verbose=FALSE)

# Saving item parameters as a matrix
parameters <- coef(model.2pl, IRTpars = TRUE, simplify=TRUE)$items
parameters <- as.matrix(parameters)
colnames(parameters) <- c("a","b","c","d")

# Saving theta values as a matrix
theta <- fscores(model.2pl, method = "EAP")
theta <- as.matrix(theta)
```

Now we can check out the test information function for the scale. Figure \@ref(fig:tifplot) indicates that the scale is mostly informative between $\theta = -3$ and $\theta = -2$. 

```{r, eval = FALSE}
plot(model.2pl, type = 'infoSE', theta_lim=c(-5,5), 
     auto.key = list(points=TRUE, lines=TRUE, columns=2, space = "top"),
     par.settings = list(superpose.line = list(col = "black", lty = 1:2, lwd = 2)))
```

```{r tifplot, eval = TRUE, echo=FALSE, fig.cap="Test Information Function and Standard Error of Measurement"}
plot(model.2pl, type = 'infoSE', theta_lim=c(-5,5), 
     auto.key = list(points=TRUE, lines=TRUE, columns=2, space = "top"),
     par.settings = list(superpose.line = list(col = "black", lty = 1:2, lwd = 2)))
```

Using the item parameters and theta values we have estimated above, we will design a hypothetical CAT scenario. Our goal is to check the feasibility of using the Taylor Manifest Anxiety Scale as a computerized adaptive scale. Therefore, we will run post hoc simulations using real responses in the data. We will let the CAT system select the optimal items from the scale for each person and then compare the final theta estimates from CAT with those from the calibration that involves all 49 items. 

To run post hoc simulations, we will use the simulateRespondents function in the **catR** package [@catr]. In the first simulation, we will use the following rules:

* each person can answer up to 10 items in the scale, and 
* if a person's theta estimate is precise enough (i.e., SEM < 0.3), CAT should terminate the test, without administering all 10 items. 

We want to use Maximum Fisher Information (MFI) to select the starting item and the remaining items. That is, the CAT system will choose the most informative item given a person's interim theta estimate. Also, we want to use expected a posteriori (EAP) as the method for for estimating interim theta values as well as final theta values. 

To keep our example simple, we will choose a random sample of 750 persons (out of 4474 persons) and test the CAT system with this sample. 

```{r, eval = FALSE}
library("catR")

set.seed(2021)

persons <- sample.int(750, n = nrow(theta))

sim1 <- simulateRespondents(thetas = theta[persons,],
                            itemBank = parameters, 
                            responsesMatrix = data[persons,],
                            # Starting rules for CAT  
                            start = list(startSelect="MFI"),
                            # Test administration rules for CAT
                            test = list(method="EAP", itemSelect="MFI"),
                            # Stopping rule for CAT
                            stop = list(rule = c("precision", "length"), thr = c(0.3, 10)),
                            # Final ability estimation
                            final = list(method = "EAP")
)
```

```{r, eval = TRUE, echo=FALSE, warning=FALSE, message=FALSE, results = 'hide'}
set.seed(2021)

persons <- sample.int(750, n = nrow(theta))

sim1 <- simulateRespondents(thetas = theta[persons,],
                            itemBank = parameters, 
                            responsesMatrix = data[persons,],
                            # Starting rules for CAT  
                            start = list(startSelect="MFI"),
                            # Test administration rules for CAT
                            test = list(method="EAP", itemSelect="MFI"),
                            # Stopping rule for CAT
                            stop = list(rule = c("precision", "length"), thr = c(0.3, 10)),
                            # Final ability estimation
                            final = list(method = "EAP")
)
```

Now, let's see the simulation output.

```{r}
# Statistical summary of results
print(sim1)
```

```{r, eval=FALSE}
# Visual summary of results
plot(sim1)
```

```{r, echo = FALSE, fig.cap="Simulation Results", fig.width=7, fig.height=8}
# Visual summary of results
knitr::include_graphics("sim1_plot.png")
```


## Conclusion

xx
