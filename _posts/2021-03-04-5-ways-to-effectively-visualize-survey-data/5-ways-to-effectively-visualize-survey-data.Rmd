---
title: "5 Ways to Effectively Visualize Survey Data"
description: |
  When presented visually, survey results become much more interesting than some numbers squeezed into a boring table. Data visualizations help your audience view and understand key insights in the results. There are many data visualization tools to present survey results visually, including bar charts, pie charts, and line charts. In this post, I demonstrate 5 alternative ways to visualize survey results. 
  ```{r, include=FALSE}
  bytes <- file.size("5-ways-to-effectively-visualize-survey-data.Rmd")
  words <- bytes/10
  minutes <- words/200
  ``` 
  (`r round(minutes)` min read)
author:
  - name: Okan Bulut
    url: http://www.okanbulut.com/
    affiliation: University of Alberta
    affiliation_url: https://www.ualberta.ca
    orcid_id: 0000-0001-5853-1267
date: 03-04-2021
categories:
  - survey
  - data visualization
preview: survey.png
bibliography: survey.bib
csl: apa.csl
output:
  distill::distill_article:
    self_contained: false
    toc: true
draft: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, warning = FALSE, message = FALSE)
suppressWarnings({
  library("rmarkdown")
  library("kableExtra")
  library("emo")
  library("dplyr")
  library("ggplot2")
  library("corrplot")
  library("ggcorrplot")
  library("likert")
  library("naniar")
  library("reshape2")
  library("ggalluvial")
  library("mirt")
  library("cowplot")
})
```


![Photo by [200degrees](https://pixabay.com/users/200degrees-2051452/) on [pixabay](https://pixabay.com/)](survey.png)

## Introduction

As a visual learner, I often use data visualization to present the results of surveys and other types of self-report measures (e.g., psychological scales). In the 2019 annual meeting of [the Canadian Society for the Study of Education (CSSE)](https://csse-scee.ca/), I gave a half-day workshop on how to visualize assessment and survey items effectively (the workshop slides are available on [my GitHub page](https://github.com/okanbulut/dataviz/raw/master/CSSE_Workshop.pdf))^[The other training materials are available at <https://github.com/okanbulut/dataviz>.]. My goal was to demonstrate readily-available tools that can be used for creating effective visualizations with survey and assessment data. Since my CSSE workshop in 2019, I have come across several other tools that can be quite useful for presenting survey results visually. So, I have decided to share them with other researchers in social and behavioral sciences through a blog post.   

There are several ways to visualize data, depending on the type of variables as well as the message to be conveyed to the audience. Figure \@ref(fig:dataviz) presents some guidelines regarding which type of visualization to choose depending on the purpose of visualization, type of variables, and the number of variables. Similar guidelines for data visualization are available on the [Venngage](https://venngage.com/blog/how-to-choose-the-best-charts-for-your-infographic/) website. Also, I definitely recommend you to check out Darkhorse Analytics' blog post "[Data Looks Better Naked](https://www.darkhorseanalytics.com/blog/data-looks-better-naked)". They demonstrate how to create effective visualizations by eliminating redundancy in figures and charts. 

```{r dataviz, echo = FALSE, fig.cap="Types of data visualization (Source: https://extremepresentation.com/)", out.extra="class=external", fig.width=6, fig.height=4, layout="l-body-outset"}
# Visual summary of results
knitr::include_graphics("dataviz.png")
```

In this post, I will use real data from a questionnaire included in OECD's [Programme for International Student Assessment (PISA)](http://www.oecd.org/pisa/). PISA is an international, large-scale assessment administered to 15-year-old students across many countries and economies around the world. In 2015, nearly 540,000 students from 72 countries participated in PISA. After finishing reading, math, and science assessments, students also complete a questionnaire with several items focusing on their learning in school, their attitudes towards different aspects of learning, and non-cognitive/metacognitive constructs. Using students' responses in the questionnaire, I will demonstrate five alternative tools to visualize survey data. 


## Example

In this example, we will use a subset of the PISA 2015 dataset that includes students' responses to some survey items as well as demographic variables (e.g., age, gender, and immigration status). The sample only consists of students who participated in PISA 2015 from Alberta, Canada ($n = 2,133$). The data set is available in a .csv format [here](https://raw.githubusercontent.com/okanbulut/blog/master/data_and_codes/PISA_Alberta.csv).

There are 10 Likert-type survey items **potentially** measuring students' attitudes towards teamwork. The first eight items share the question statement: "To what extent do you disagree or agree about yourself?". The last two items are independent. Now let's see all of the items included in the data. 

```{r ch0, echo=FALSE}
quest <- read.csv("questions.csv", header = TRUE, na.strings = 999)
colnames(quest) <- c("Question ID", "Question Statement")

kbl(quest) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                full_width = TRUE, position = "left")
```

Students can answer the items by selecting one the following response options or skip them without choosing a response option (999 in the data):

* 1 = Strongly disagree
* 2 = Disagree
* 3 = Agree
* 4 = Strongly agree

We will begin the analysis by reading the data in R and previewing the first few rows. 

```{r ch1, eval=FALSE}
# Read the data in R
data <- read.csv("PISA_Alberta.csv", header = TRUE, na.strings = 999)

# Preview the data
head(data)
```

```{r ch2, echo=FALSE}
# Read the data in R
data <- read.csv("PISA_Alberta.csv", header = TRUE, na.strings = 999)
paged_table(data, options = list(cols.print = 12))
```

In the following sections, I will demonstrate how to visualize the items in the PISA data set. The visualizations focus on either individual items or the relationship among the items. 


### Correlation Matrix Plot

We will begin the visualization process by creating a correlation matrix plot. This plot takes the correlation matrix of items as an input and transforms it into a colored table similar to a heatmap. Negative and positive correlations are represented by different colors. Also, the darkness (or lightness) of the colors indicate the strength of pairwise correlations. Using this plot, we can:

* understand the direction and strength of the relationships among the items,
* detect problematic items (i.e., items that are weakly correlated with the rest of the items), and
* identify the items that may require reverse-coding due to inconsistent phrasing (e.g., negative phrasing in some items).

To create a correlation matrix plot, we can use either **corrplot** [@corrplot] or **ggcorrplot** [@ggcorrplot]. First, we will select the survey items (those starting with ST082 and ST034 in the data). Next, we will save pairwise correlations among the items (i.e., a 10x10 matrix of correlations). Finally, we will create a correlation matrix plot using the two aforementioned packages. For preparing the data for the data visualizations, we will use the **dplyr** package [@dplyr].


```{r ch3.1, eval=FALSE}
# Activate the dplyr package
library("dplyr")

# Correlation matrix of items
cormat <- data %>%
  select(starts_with(c("ST082", "ST034"))) %>%
  cor(., use = "pairwise.complete.obs")
```

Now using "cormat", let's create our correlation matrix plot using **corrplot**. In the corrplot function, order = "hclust" applies hierarchical clustering to group the items together based on their correlations with each other. The other option, addrect = 2, refers to the number of rectangles that we want to draw around the item clusters. In our example, I suspect that there will be two clusters: one for the first 8 items (focusing on teamwork) and another for the last 2 items (focusing on being liked by friends). Item clusters in Figure \@ref(fig:ch4) seem to confirm our suspicion. 


```{r ch3.2, eval=FALSE}
# Activate the corrplot package
library("corrplot")

# Correlation matrix plot
corrplot(cormat, # correlation matrix
         order = "hclust", # hierarchical clustering of correlations
         addrect = 2) # number of rectangles to draw around clusters
```


```{r ch4, echo=FALSE, fig.width=8, fig.height=5, fig.cap="Correlation matrix plot of the PISA survey items (using corrplot)", layout="l-body-outset"}
# Correlation matrix of items
cormat <- data %>%
  select(starts_with(c("ST082", "ST034"))) %>%
  cor(., use = "pairwise.complete.obs")

# Correlation matrix plot
corrplot(cormat, order = "hclust", addrect = 2)
```

Next, we will use **ggcorrplot** to create a correlation matrix plot. The procedure is very similar. By using type = "lower", we will only visualize the lower diagonal part of the correlation matrix. 

```{r ch5, eval=FALSE}
library("ggcorrplot")

# Correlation matrix plot
ggcorrplot(cormat, # correlation matrix
           type = "lower", # print the lower part of the correlation matrix
           hc.order = TRUE, # hierarchical clustering of correlations
           lab = TRUE) # add correlation values as labels
```


```{r ch6, echo=FALSE, fig.width=8, fig.height=6, fig.cap="Correlation matrix plot of the PISA survey items (using ggcorrplot)", layout="l-body-outset"}
library("ggcorrplot")

# Correlation matrix plot
ggcorrplot(cormat, # correlation matrix
           type = "lower", # print the lower part of the correlation matrix
           hc.order = TRUE, # hierarchical clustering of correlations
           lab = TRUE) # add correlation values as labels
```

### UpSet Plot

```{r ch7, eval=FALSE}
data <- mutate(data,
               gender = ifelse(ST004D01T == 1, "Female", "Male"),
               immigration = ifelse(is.na(IMMIG), NA, ifelse(IMMIG == 1, "Native", 
                                           ifelse(IMMIG == 2, "Second-Generation", 
                                                  "First-Generation")))) %>%
  rename(grade = ST001D01T,
         student = CNTSTUID,
         age = AGE) %>%
  select(-ST004D01T, -IMMIG)
```


```{r ch8,eval=FALSE}
library("naniar")

# Select only the survey items
gg_miss_upset(data[, 6:15], nsets = 10)
```


```{r ch9,echo=FALSE, fig.width=6, fig.height=5, layout="l-body-outset", fig.cap="An UpSet plot showing missing data patterns in the PISA dataset"}
gg_miss_upset(data[, 6:15], nsets = 10)
```

The **UpSetR** package also offers [a Shiny app](https://gehlenborglab.shinyapps.io/upsetr/) to generate UpSet plots without any coding in R. 


### Stacked Bar Chart

```{r ch10, eval=TRUE, fig.width=8, fig.height=5, layout="l-body-outset", fig.cap="A plot of Likert items in the PISA dataset"}
library("likert")

items <- select(data, starts_with(c("ST082")))

names(items) <- c(
  ST082Q01="I prefer working as part of a team to working alone.",
  ST082Q02="I am a good listener.",
  ST082Q03="I enjoy seeing my classmates be successful.",
  ST082Q08="I take into account what others are interested in.",
  ST082Q09="I find that teams make better decisions than individuals.",
  ST082Q12="I enjoy considering different perspectives.",
  ST082Q13="I find that teamwork raises my own efficiency.",
  ST082Q14="I enjoy cooperating with peers.")

likert_recode <- function(x) {
  y <- ifelse(is.na(x), "Missing",
              ifelse(x == 1, "Strongly disagree",
                     ifelse(x == 2, "Disagree",
                            ifelse(x == 3, "Agree", "Strongly agree"))))
  
  y <- factor(y, levels = c("Strongly disagree", "Disagree", "Missing", 
                            "Agree", "Strongly agree"))
  
  return(y)
}

items_likert <- items %>%
  mutate_all(likert_recode) %>%
  likert()

plot(items_likert, ordered=FALSE, group.order=names(items))
```


### Alluvial Plot

```{r ch11, eval=FALSE}
library("reshape2")
library("ggplot2")
library("ggalluvial")

data_long <- data %>%
  # Melt data to long format
  melt(data = .,
       id.vars = c("student", "grade", "age", "gender", "immigration"),
       variable.name = "question",
       value.name = "response") %>%
  # Recode numerical responses to character strings
  mutate(response2 = (ifelse(is.na(response), "Missing",
                             ifelse(response == 1, "Strongly disagree",
                                    ifelse(response == 2, "Disagree",
                                           ifelse(response == 3, "Agree", "Strongly agree"))))),
         
         response3 = factor(response2, levels = c("Missing", "Strongly disagree", "Disagree", 
                                                  "Agree", "Strongly agree"))
         
  ) %>%
  # Summarize the data
  group_by(gender, question, response3) %>%
  summarise(Freq = n())
  

ggplot(data_long,
       aes(y = Freq, axis1 = question, axis2 = gender, axis3 = response3)) +
  geom_alluvium(aes(fill = gender), width = 1/12) +
  geom_stratum(width = 1/12, fill = "black", color = "grey") +
  geom_label(stat = "stratum", aes(label = after_stat(stratum))) +
  scale_x_discrete(limits = c("Gender", "Dept"), expand = c(.05, .05)) +
  scale_fill_brewer(type = "qual", palette = "Set1") +
  ggtitle("UC Berkeley admissions and rejections, by sex and department")
```


### Item-Person Map

```{r ch12, eval=TRUE, fig.width=8, fig.height=6, layout="l-body-outset", fig.cap="An item-person map of the items"}

# Save the items as a separate dataset
items <- select(data, starts_with(c("ST082")))

# Change responses from 1-2-3-4 to 0-1-2-3 by subtracting 1
items2 <- apply(items, 2, function(x) x-1)

# Apply the Partial Credit Model
mod <- mirt(items2, 1, itemtype = "Rasch", technical = list(removeEmptyRows=TRUE),
            verbose = FALSE)

# Function to draw and item-person map
# mod is a mirt model returned from the mirt function
# For meaningful results, Partial Credit Model must be
# used in estimating item thresholds.

itempersonmap <- function(mod) {
  require("mirt")
  require("dplyr")
  require("reshape2")
  require("ggplot2")
  require("cowplot")
  
  pars <- as.data.frame(coef(mod, IRTpars = TRUE, simplify = TRUE)$items)
  
  pars <- pars %>%
    select(-a) %>%
    mutate(item = row.names(pars)) %>%
    melt(data = ., 
         id.vars = "item",
         variable.name = "threshold",
         value.name = "parameter")
  
  theta <- as.data.frame(fscores(mod)) %>%
    rename(theta = F1)
  
  # Histogram of latent trait distribution
  p1 <- ggplot(data = theta,
               aes(x = theta)) +
    geom_histogram(bins = 30, fill = "royalblue2", colour = "lightgray") +
    theme_bw(base_size = 13) +
    theme(axis.text.x = element_text(angle = 45)) +
    labs(x = "Latent Trait", y = "") +
    scale_x_continuous(limits = c(-5, 5), breaks = seq(-5, 5, by = 1)) +
    coord_flip() + scale_y_reverse()
  
  # Dot and line plot of item thresholds
  p2 <- ggplot(data = pars, 
               aes(x = item, y = parameter)) +
    geom_line() +
    geom_point(aes(shape = threshold), size = 3, colour = "indianred1") +
    theme_bw(base_size = 13) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1),
          legend.position = "none") +
    labs(x = "", y = "Item Thresholds", shape = "Threshold") +
    scale_y_continuous(position = "right", limits = c(-5, 5), breaks = seq(-5, 5, by = 1))
  
  # Combine the plots together
  plot_grid(p1, p2, align = "h")
  
}

# Create the item-person map
itempersonmap(mod)
```
## Conclusion

xxx

