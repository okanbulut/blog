---
title: "Text Vectorization Using Python: TF-IDF"
description: |
  We continue exploring text vectorization in Python. In the second part of our post, we will explain term frequencyâ€“inverse document frequency (TF-IDF) and demonstrate how to use vectorize text using TF-IDF in Python. xxx
  ```{r, include=FALSE}
  bytes <- file.size("text-vectorization-using-python-tf-idf.Rmd")
  words <- bytes/10
  minutes <- words/200
  ``` 
  (`r round(minutes)` min read)
author:
  - name: Sevilay Kilmen 
    url: https://www.researchgate.net/profile/Sevilay-Kilmen-2 
    affiliation: Abant Izzet Baysal University
    affiliation_url: http://www.ibu.edu.tr/en
    orcid_id: 0000-0002-5432-7338
  - name: Okan Bulut
    url: http://www.okanbulut.com/
    affiliation: University of Alberta
    affiliation_url: https://www.ualberta.ca
    orcid_id: 0000-0001-5853-1267
date: 12-06-2021
categories:
  - data science
  - text mining
  - natural language processing
preview: pexels.jpg
output:
  distill::distill_article:
    self_contained: false
    toc: true
draft: true
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, warning = FALSE, message = FALSE)
suppressWarnings({
  # Add all the packages you will use in the article here
  library("rmarkdown")
  library("kableExtra")
  # https://github.com/hadley/emo
  devtools::install_github("hadley/emo")
  library("emo")
  library("reticulate")
})
```

![Photo by [Ri_Ya](https://pixabay.com/users/ri_ya-12911237/) on [Pixabay](https://pixabay.com/)](pixabay.jpg)

## Introduction

xxx 

## Example 

In this example, we will continue using the data set from one of the Hewlett Foundation's automated scoring competition: [Short Answer Scoring](https://www.kaggle.com/c/asap-sas). The data set includes students' responses to a set of short-answer items and scores assigned by human raters. On average, each answer is approximately 50 words in length. The data set (train_rel_2.tsv) is available [here](https://raw.githubusercontent.com/okanbulut/blog/master/data_and_codes/train_rel_2.tsv) as a tab-separated value (TSV) file. The data set consists of the following variables: 

* **Id**: A unique identifier for each individual student essay.
* **EssaySet**: 1-10, an id for each set of essays.
* **Score1**: The human rater's score for the answer. This is the final score for the answer and the score that you are trying to predict.
* **Score2**: A second human rater's score for the answer. This is provided as a measure of reliability, but had no bearing on the score the essay received.
* **EssayText**: The ASCII text of a student's response.

In this example, we are using "Essay Set 1", in which students were provided with a prompt describing a science experiment. The students were required to identify the missing information that is important to increase the replicability of the experiment procedures described in the prompt. 

Firs,t we will import the data set into Python and then preview the first five rows.

```{python chunk1, echo=TRUE, eval=TRUE}
# Import pandas for dataframe 
# Import pprint for printing the outcomes 
import pandas as pd 
from pprint import pprint 

# Import train_rel_2.tsv into Python
with open('train_rel_2.tsv', 'r') as f:
    lines = f.readlines()
    columns = lines[0].split('\t')
    data = []
    response_id= []
    score = []
    for line in lines[1:]:
        temp = line.split('\t')
        if temp[1] == '1':
            data.append(temp[-1])
            response_id.append(int(temp[0]))
            score.append(int(temp[2]))
        else: 
            None

# Construct a dataframe ("doc") which includes the response_id, responses, and the score        
doc = pd.DataFrame(list(zip(response_id, data, score)))
doc.columns = ['id', 'response', 'score']

# Preview the first response in the data set
print('Sample response 1:')
pprint(doc.response.values[0])
doc.head(5)
```

xxx














