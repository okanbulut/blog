---
title: "Visualizing Machine Learning Models"
description: |
  Model visualization plays an important part in order to explore machine learning algorithms in detail. In this post, we show you one of the R packages that we have found very useful to perform machine learning model visualization: **DALEX** [@dalex]. With the **DALEX** package, you can make comparisons across machine learning models to decide which model outperforms others and why.
  ```{r, include=FALSE}
  bytes <- file.size("visualizing-machine-learning-models.Rmd")
  words <- bytes/10
  minutes <- words/200
  ``` 
  (`r round(minutes)` min read)
author:
  - name: Okan Bulut
    url: http://www.okanbulut.com/
    affiliation: University of Alberta
    affiliation_url: https://www.ualberta.ca
    orcid_id: 0000-0001-5853-1267
  - name: Seyma Nur Yildirim-Erbasli 
    url: https://www.ualberta.ca
    affiliation: University of Alberta
    affiliation_url: https://www.ualberta.ca
    orcid_id: 0000-0002-8010-9414
date: "`r Sys.Date()`"
categories:
  - machine learning
  - classification 
  - data visualization
preview: algorithm.jpg
bibliography: references.bib
csl: apa.csl
output:
  distill::distill_article:
    self_contained: false
    toc: true
draft: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, warning = FALSE, message = FALSE)
suppressWarnings({
  library("rmarkdown")
  library("kableExtra")
  library("emo")
  library("caret")
  library("DALEX")
  library("ggplot2")
  library("patchwork")
})
```

![Photo by [Gerd Altmann](https://pixabay.com/users/geralt-9301/) on [pixabay](https://pixabay.com/)](algorithm.jpg)

## Introduction

In recent years, advanced machine learning algorithms have been studied in different contexts of education. The literature shows that most of the researchers in education perform machine learning models for classification (or prediction) problems such as student engagement [e.g., @hew2018understanding], performance [e.g., @xu2017machine], and dropout [e.g., @tan2015prediction]. This growing and important use of machine learning models require better comparison among models to understand and interpret which and why one model outperforms another. Comparison and evaluation of the classification models only based on recall, precision, accuracy, and area under the curve may not be enough to obtain a sufficient understanding of their statistical details and performances. In this post, we show you one of the R packages that can be used to visualize and interpret machine learning models: **DALEX** [@dalex]. **DALEX** package stands for **moDel Agnostic Language for Exploration and eXplanation**. It can be used for any regression and classification machine learning tasks. It consists of very useful functions to help interpret, explain and compare different machine learning models. With the **DALEX** package, you can investigate residual diagnostics, feature importance, the relationship between feature and outcome variable, and a single prediction. 

Now, let's get started `r emo::ji("trend")`.

## Example 

In this post, we use the Turkish sample of the PISA 2015 dataset to demonstrate model visualization techniques for machine learning models through a binary classification of reading performance (i.e., high performance vs. low performance). ^[You can also follow this post for a regression model task.] The data set is available [here](https://raw.githubusercontent.com/okanbulut/blog/master/data_and_codes/PISA_Turkey.csv). The variables in the data set are:

Variable      | Description
------------- | -------------
gender        | Gender
grade         | Grade
computer      | Computer at home?
internet      | Internet at home?
desk          | Desk at home?
own.room      | Own a room at home?
quiet.study   | Quiet study area at home?
book.sch      | School books
tech.book     | Technical books
art.book      | Art book
reading       | Student reading scores in PISA 2015
   
First, letâ€™s import the data into R, view its content, and remove missing cases.

```{r ch1, eval=FALSE}
pisa <- read.csv("PISA_Turkey.csv", header = TRUE)
head(pisa)
```

```{r ch2, eval=TRUE, echo=FALSE}
pisa <- read.csv("PISA_Turkey.csv", header = TRUE)
paged_table(pisa, options = list(cols.print = 12))
```

Second, we will remove missing cases from the data.

```{r ch3, echo=TRUE}
pisa <- na.omit(pisa)
```

Second, we convert gender and grade to numeric variables. Also, in the **DALEX** package, the outcome variable needs to be a numeric vector for both regression and classification tasks. Thus, for our current example, we convert the reading performance to a binary classification based on the sample mean: 1 (i.e., high performing) vs. 0 (i.e., low performing).

```{r ch4, echo=TRUE}
# Convert gender to a numeric variable
pisa$gender = (as.numeric(sapply(pisa$gender, function(x) {
  if(x=="Female") "1"
  else if (x=="Male") "0"})))

# Convert grade to a numeric variable
pisa$grade = (as.numeric(sapply(pisa$grade, function(x) {
  if(x=="Grade 7") "7"
  else if (x=="Grade 8") "8"
  else if (x=="Grade 9") "9"
  else if (x=="Grade 10") "10"
  else if (x=="Grade 11") "11"
  else if (x=="Grade 12") "12"})))

# Convert reading performance to a binary variable based on the average score 
# 1 represents high and 0 represents low performance
pisa$reading <- factor(ifelse(pisa$reading >= mean(pisa$reading), 1, 0))

# View the frequencies for high and low performance groups
table(pisa$reading)
```

Now, we train three machine learning models: random forest, logistic regression, and support vector machines. As the focus of our post is on how to visualize machine learning algorithms to interpret classification results, we train these models without hyperparameter tuning. We use the **caret** package [@caret] *createDataPartition()* function to create training and testing datasets. For modeling, we split the data into 70% for training and 30% for testing.

```{r}
# Set the seed and split the data into training and testing sets
set.seed(1)
index <- createDataPartition(pisa$reading, p = 0.7, list = FALSE)
train <- pisa[index, ]
test  <- pisa[-index, ]
```

Next, we use the **caret** package *train()* function to fit three classification models through 5-fold cross-validation.

```{r}
# 5-fold cross-validation
control = trainControl(method="repeatedcv", number = 5, savePredictions=TRUE)

# Random Forest
mod_rf = train(reading ~ .,
               data = train, method='rf', trControl = control)

# Generalized Linear Model
mod_glm = train(reading ~ .,
                data = train, method="glm", family = "binomial", trControl = control)

# Support Vector Machines
mod_svm <- train(reading ~.,
                 data = train, method = "svmRadial", prob.model = TRUE, trControl=control)
```

Now, we are ready to explore the **DALEX** package. The first step of using the **DALEX** package is to define explainers for machine learning models. For this, we write a custom *predict* function with two arguments: *model* and *newdata*. This function returns a vector of numeric values. Then, we create an explainer for each machine learning model using the *explainer()* function from the **DALEX** package with the *testing* dataset and the *predict* function. When we convert machine learning models to an *explainer* object, they contain a list of the training and metadata on the machine learning model.

```{r}
# create a custom predict function
p_fun <- function(object, newdata){predict(object, newdata=newdata, type="prob")[,2]}

# convert the outcome variable to a numeric binary vector
yTest <- as.numeric(as.character(test$reading))

# create explainer objects for each machine learning model
explainer_rf  <- explain(mod_rf, label = "RF",
                         data = test, y = yTest,
                         predict_function = p_fun,
                         verbose = FALSE)

explainer_glm <- explain(mod_glm, label = "GLM",
                         data = test, y = yTest,
                         predict_function = p_fun,
                         verbose = FALSE)

explainer_svm <- explain(mod_svm, label = "SVM",
                         data = test, y = yTest,
                         predict_function = p_fun,
                         verbose = FALSE)
```

### Model Performance

With the **DALEX** package, one of the things we can do is to analyze model performance as the distribution of residuals. Here, we consider the differences between observed and predicted probabilities as residuals. *model_performance()* function calculates predictions and residuals for the testing dataset.

```{r}
mp_rf  <- model_performance(explainer_rf)
mp_glm <- model_performance(explainer_glm)
mp_svm <- model_performance(explainer_svm)

# print the models
mp_rf
mp_glm
mp_svm
```

Based on the performance measures of these three models (i.e., recall, precision, f1, accuracy, and AUC) from the above output, we can say that they seem very similar. However, when we check the residual plots, we see how similar or different they are in terms of the residuals. Residual plots show the cumulative distribution function for absolute values from residuals and they can be generated for one or more models. Here, we use the *plot()* function to get a comparison of models. This plot allows us to make an easy comparison of absolute residual values across models.

```{r}
p1 <- plot(mp_rf, mp_glm, mp_svm)
p1
```

From the reverse cumulative of the absolute residual plot, we can see that there is a higher number of residuals in the head of the SVM residual distribution. It shows a higher number of large residuals compared to the other two models. However, RF has a higher number of large residuals than the other models in the tail of the residual distribution.

In addition to the cumulative distributions of absolute residuals, we can compare the distribution of residuals with boxplots by setting the *geom = "boxplot"*.

```{r}
p2 <- plot(mp_rf, mp_glm, mp_svm, geom = "boxplot")
p2
```

According to boxplots of absolute residuals, RF seems to have the lowest median absolute residual value. Even though the GLM model has the highest AUC score, the RF model performs best when considering the median absolute residuals.

```{r}
p1 <- plot(mp_rf, mp_glm, mp_svm, geom = "histogram") 
p2 <- plot(mp_rf, mp_glm, mp_svm, geom = "prc") 
p1 + p2
```

### Variable Importance

In machine learning models, one of the important interpretations is to understand which predictor variables are more important on the predicted variable. Using the **DALEX** package, we can better understand which variables are more influential on the predicted outcome. *variable_importance()* function computes variable importances through permutation, and they can also be plotted. In the plot, the left edge of the interval is the loss function for the full model. The length of the interval corresponds to variable importance. Now letâ€™s see the feature importance plots.

```{r}
vi_rf <- variable_importance(explainer_rf, loss_function = loss_root_mean_square)
vi_glm <- variable_importance(explainer_glm, loss_function = loss_root_mean_square)
vi_svm <- variable_importance(explainer_svm, loss_function = loss_root_mean_square)
plot(vi_rf, vi_glm, vi_svm)
```

The left edge of the x-axis in the feature importance plot illustrates the difference in the RMSE loss across the models. Thus, GLM model has the lowest RMSE, and RF has the highest RMSE. According to the results, if we list the first two most influential variables on the predicted outcome, grade and school books seem to largely influence all three models.

```{r}
vip_rf  <- model_parts(explainer = explainer_rf,  B = 50, N = NULL)
vip_glm  <- model_parts(explainer = explainer_glm,  B = 50, N = NULL)
vip_svm <- model_parts(explainer = explainer_svm, B = 50, N = NULL)

plot(vip_rf, vip_glm, vip_svm) +
  ggtitle("Mean variable-importance over 50 permutations", "") 
```

### Partial Depedence Plot

With the **DALEX** package, we can also create explainers that are designed to better understand the relationship between a variable and model output through Partial Dependence Plots (PDP) and Accumulated Local Effects (ALE). They show whether the relationship between the target and a feature is linear or not and how each predictor affects the predictions. However, their one disadvantage is that they can only be performed for each variable one by one. *model_profile()* function with the parameter *type = "partial"* calculate PDP.

```{r}
pdp_rf <- model_profile(explainer_rf, variable = "grade", type = "partial")
pdp_glm <- model_profile(explainer_glm, variable = "grade", type = "partial")
pdp_svm <- model_profile(explainer_svm, variable = "grade", type = "partial")
plot(pdp_rf, pdp_glm, pdp_svm)
```

The above PDP plot helps us to understand how grade affects the classification of reading performance. It shows that the probability is low until grade 9 but then increases for all models. However, it decreases after grade 10 for RF and SVM models.

### Acumulated Local Effects Plot

ALE plots are the extension of PDP, which is more suited for correlated variables. *model_profile()* function with the parameter *type = "accumulated"* calculate the ALE curve. We recommend using ALE plots because features are usually correlated to some extent, and ALE plots are unbiased when features are correlated.

```{r}
ale_rf  <- model_profile(explainer_rf, variable = "grade", type = "accumulated")
ale_glm  <- model_profile(explainer_glm, variable = "grade", type = "accumulated")
ale_svm  <- model_profile(explainer_svm, variable = "grade", type = "accumulated")
plot(ale_rf, ale_glm, ale_svm)
```

```{r}
plot(model_profile(explainer_rf, variable = "grade"),
     model_profile(explainer_glm, variable = "grade"),
     model_profile(explainer_svm, variable = "grade")) +
  ggtitle("Predictions for Grade")
```

## Conclusion

In this post, we wanted to share with you the use of the **DALEX** package and show what you can obtain about the machine learning models beyond the conventional performance measures in order for a better understanding, interpretation, and comparison. In addition to the conventional performance measures, the package provides the residual diagnostics of the machine learning models that can be identified by calculating and plotting residuals. It also helps explore the feature importance to decide the more influential variables across all models. Moreover, it provides the relationship between each predictor and outcome variable as well as the effect of each predictor on the outcome variable. These features of the **DALEX** package will help you discover the results of the machine learning models that you probably have not considered before. More examples are available on the **DALEX** authors' book [@dalexbook], which is available online at <http://ema.drwhy.ai/>.


